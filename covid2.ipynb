{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "covid2",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPTxb6ap8qnbslCP3F85TM1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lassewardenaer/covid/blob/main/covid2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFFLZ3lXp5JE"
      },
      "outputs": [],
      "source": [
        "# Example code for training model and creating submission file.\n",
        "# Author: Peter Sadowski Jan 22 2022\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pylab as plt\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from category_encoders.one_hot import OneHotEncoder #pip install category_encoders\n",
        "import multiprocessing as mp \n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Load training data.\n",
        "df_train = pd.read_csv('./train.csv.zip', nrows=20000000) # Can read from zip files directly.\n",
        "df_train = df_train.replace({'death_yn':{np.nan:0}}) # Assume no info means survived.\n",
        "\n",
        "# Load test data.\n",
        "df_test = pd.read_csv('./test.csv.zip')\n",
        "df_all_smoke = pd.read_csv('./smoking_data.csv')\n",
        "\n",
        "state_to_smoke = dict()\n",
        "for state in df_all_smoke['LocationAbbr'].values:\n",
        "  state_to_smoke[state] = df_all_smoke[df_all_smoke['LocationAbbr'] == state]['Data_Value'].to_numpy()[0]\n",
        "\n",
        "state_to_smoke['VI'] = 0\n",
        "state_to_smoke['NJ'] = 0\n",
        "state_to_smoke[np.nan] = 0\n",
        "smoke_no_nan = [x for x in list(state_to_smoke.values())]\n",
        "state_to_smoke['VI'] = np.sum(smoke_no_nan) // (len(state_to_smoke)-2)\n",
        "state_to_smoke['NJ'] = np.sum(smoke_no_nan) // (len(state_to_smoke)-2)\n",
        "state_to_smoke[np.nan] = np.sum(smoke_no_nan) // (len(state_to_smoke)-2)\n",
        "\n",
        "state_to_smoke_rate_train = [state_to_smoke[state] for state in df_train['res_state']]\n",
        "df_smoke_train = pd.DataFrame({'smoke_data': state_to_smoke_rate_train})\n",
        "\n",
        "state_to_smoke_rate_test = [state_to_smoke[state] for state in df_test['res_state']]\n",
        "df_smoke_test = pd.DataFrame({'smoke_data': state_to_smoke_rate_test})\n",
        "\n",
        "df_train = df_train.drop(\n",
        "    ['case_month',\n",
        "     'res_state',\n",
        "     'res_county',\n",
        "     'case_positive_specimen_interval',\n",
        "     'case_onset_interval',\n",
        "     'process',\n",
        "     'exposure_yn',\n",
        "     'labconfirmed_yn',\n",
        "     'symptomatic_yn'],\n",
        "      axis=1)\n",
        "\n",
        "df_test = df_test.drop(\n",
        "    ['case_month',\n",
        "     'res_state',\n",
        "     'res_county',\n",
        "     'case_positive_specimen_interval',\n",
        "     'case_onset_interval',\n",
        "     'process',\n",
        "     'exposure_yn',\n",
        "     'labconfirmed_yn',\n",
        "     'symptomatic_yn'],\n",
        "      axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = df_train.replace({'icu_yn':{np.nan:0}})\n",
        "df_train = df_train.replace({'icu_yn':{'0':0}})\n",
        "df_train = df_train.replace({'icu_yn':{'1':1}})\n",
        "df_train = df_train.replace({'icu_yn':{'nul':0}})\n",
        "\n",
        "df_test = df_test.replace({'icu_yn':{np.nan:0}})\n",
        "df_test = df_test.replace({'icu_yn':{'0':0}})\n",
        "df_test = df_test.replace({'icu_yn':{'1':1}})\n",
        "df_test = df_test.replace({'icu_yn':{'nul':0}})\n",
        "\n",
        "df_smoke_train = df_smoke_train.replace({'smoke_data':{np.nan:state_to_smoke['VI']}})\n",
        "df_smoke_test = df_smoke_test.replace({'smoke_data':{np.nan:state_to_smoke['VI']}})\n",
        "\n",
        "df_train = df_train.replace({'age_group':{'Unknown':np.nan}})\n",
        "df_train = df_train.replace({'age_group':{'Missing':np.nan}})\n",
        "\n",
        "df_test = df_test.replace({'age_group':{'Unknown':np.nan}})\n",
        "df_test = df_test.replace({'age_group':{'Missing':np.nan}})\n",
        "\n",
        "df_train = df_train.replace({'hosp_yn':{np.nan:0}})\n",
        "df_test = df_test.replace({'hosp_yn':{np.nan:0}})\n",
        "\n",
        "df_train = df_train.replace({'underlying_conditions_yn':{np.nan:0}})\n",
        "df_test = df_test.replace({'underlying_conditions_yn':{np.nan:0}})"
      ],
      "metadata": {
        "id": "KdUxxoMp4xUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Cleaning of data\n",
        "\n",
        "def encode(atr, df, df_test, drop_atr):\n",
        "  oe = OneHotEncoder(return_df=True, use_cat_names=True)\n",
        "  df = oe.fit_transform(df[[atr]])\n",
        "  df_test = oe.transform(df_test[[atr]])\n",
        "  df = df.drop(drop_atr, axis=1)\n",
        "  df_test = df_test.drop(drop_atr, axis=1)\n",
        "  return [df, df_test]"
      ],
      "metadata": {
        "id": "H4UVp8Flsc1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[race_encoded, race_encoded_test] = encode('race', df_train, df_test, ['race_nan', 'race_Unknown', 'race_Missing']);\n",
        "[sex_encoded, sex_encoded_test] = encode('sex', df_train, df_test, ['sex_nan', 'sex_Unknown', 'sex_Missing']);\n",
        "[age_group_encoded, age_group_encoded_test] = encode('age_group', df_train, df_test, ['age_group_nan'])"
      ],
      "metadata": {
        "id": "_aEC5lRY96pc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merging of data\n",
        "df_train = df_train.drop(['race', 'age_group', 'ethnicity', 'sex'], axis=1)\n",
        "df_test = df_test.drop(['race', 'age_group', 'ethnicity', 'sex'], axis=1)\n",
        "\n",
        "df_train = pd.concat([df_train.reset_index(drop=True), race_encoded.reset_index(drop=True)], axis=1)\n",
        "df_train = pd.concat([df_train.reset_index(drop=True), sex_encoded.reset_index(drop=True)], axis=1)\n",
        "df_train = pd.concat([df_train.reset_index(drop=True), age_group_encoded.reset_index(drop=True)], axis=1)\n",
        "df_train = pd.concat([df_train.reset_index(drop=True), df_smoke_train.reset_index(drop=True)], axis=1)\n",
        "\n",
        "df_test = pd.concat([df_test.reset_index(drop=True), race_encoded_test.reset_index(drop=True)], axis=1)\n",
        "df_test = pd.concat([df_test.reset_index(drop=True), sex_encoded_test.reset_index(drop=True)], axis=1)\n",
        "df_test = pd.concat([df_test.reset_index(drop=True), age_group_encoded_test.reset_index(drop=True)], axis=1)\n",
        "df_test = pd.concat([df_test.reset_index(drop=True), df_smoke_test.reset_index(drop=True)], axis=1)"
      ],
      "metadata": {
        "id": "ScpPhlKmQzKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "IH_sgxeoorxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = df_train['death_yn']\n",
        "X = df_train.drop(['death_yn'], axis=1);\n",
        "X_test = df_test\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "COvWxbpFqCR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Random Forest\n",
        "parameters = {\n",
        "    'n_estimators': np.arange(10, 200, 40, dtype=int),\n",
        "    'max_depth': np.arange(1, 20, 5, dtype=int),\n",
        "    'max_leaf_nodes': np.arange(2, 250, 60, dtype=int)\n",
        "}\n",
        "\n",
        "model = RandomForestClassifier(n_jobs = mp.cpu_count())"
      ],
      "metadata": {
        "id": "wokRgRG6bGRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using k nearest neigbours\n",
        "parameters = {\n",
        "    'n_estimators': [np.arange(10, 200, 30, dtype=int)],\n",
        "    'max_depth': [np.arange(3, 10, dtype=int)]\n",
        "}\n",
        "\n",
        "model = KNeighborsClassifier()"
      ],
      "metadata": {
        "id": "HC06GT9qbjyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use of grid search to test different parameters\n",
        "gcv = GridSearchCV(model, parameters, n_jobs=-1)\n",
        "gcv.fit(X, y)\n",
        "print(gcv.best_estimator_)\n",
        "print(gcv.best_score_)\n"
      ],
      "metadata": {
        "id": "wH7gwsl9bVUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RandomForestClassifier(\n",
        "    n_jobs = mp.cpu_count(), \n",
        "    )\n",
        "model.fit(X_train, y_train)\n",
        "ypred = model.predict_proba(X_test)[:,1]"
      ],
      "metadata": {
        "id": "dotutX1YPYV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.score(X_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJ7E1dH1fdYz",
        "outputId": "94f7994d-323f-4d61-ca69-7980deb90657"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.986594\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#. Creating submission file\n",
        "submission = pd.DataFrame(ypred, columns=['prediction']) # Create new dataframe.\n",
        "submission['Id'] = submission.index  # Kaggle expects two columns: Id, prediction.\n",
        "submission.to_csv('sample_submission.csv', index=False)"
      ],
      "metadata": {
        "id": "MXzyxNI6xiL7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}